#!/usr/bin/env python3
"""
VITA-Audio å››é˜¶æ®µè®­ç»ƒè„šæœ¬
è‡ªåŠ¨åŒ–å®Œæˆæ‰€æœ‰å››ä¸ªè®­ç»ƒé˜¶æ®µï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„
"""

import os
import sys
import subprocess
import time
import argparse
from pathlib import Path
import json
from datetime import datetime

class VITAAudioTrainer:
    def __init__(self, base_model_path="/data/models/VITA-MLLM/VITA-Audio-Plus-Vanilla"):
        self.base_model_path = base_model_path
        self.project_root = Path("/home/linux/VITA/VITA-Audio")
        self.output_root = Path("/data/output/LM")
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_root.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒé…ç½®
        self.config = {
            "seq_length": 32768,
            "learning_rate": 1e-5,
            "batch_size": 4,
            "gradient_accumulation_steps": 8,
            "num_epochs": 3,
            "save_steps": 500,
            "eval_steps": 500,
            "warmup_steps": 100,
            "max_grad_norm": 1.0,
            "bf16": False,  # RTX 2080 Ti ä½¿ç”¨ fp16
            "fp16": True,
            "dataloader_num_workers": 4,
        }
        
        # å››ä¸ªé˜¶æ®µçš„é…ç½®
        self.stages = {
            1: {
                "name": "Audio-Text Alignment",
                "description": "éŸ³é¢‘-æ–‡æœ¬å¯¹é½è®­ç»ƒ",
                "config_file": "configs/sts_finetune_stage1.yaml",
                "input_model": self.base_model_path,
                "output_dir": self.output_root / f"stage1_{self.timestamp}",
                "epochs": 2,
            },
            2: {
                "name": "Single MCTP Module Training", 
                "description": "å•MCTPæ¨¡å—è®­ç»ƒ",
                "config_file": "configs/sts_finetune_stage2_demo.yaml",
                "input_model": None,  # å°†åœ¨è¿è¡Œæ—¶è®¾ç½®ä¸ºstage1çš„è¾“å‡º
                "output_dir": self.output_root / f"stage2_{self.timestamp}",
                "epochs": 3,
            },
            3: {
                "name": "Multiple MCTP Modules Training",
                "description": "å¤šMCTPæ¨¡å—è®­ç»ƒ", 
                "config_file": "configs/sts_finetune_stage3_demo.yaml",
                "input_model": None,  # å°†åœ¨è¿è¡Œæ—¶è®¾ç½®ä¸ºstage2çš„è¾“å‡º
                "output_dir": self.output_root / f"stage3_{self.timestamp}",
                "epochs": 3,
            },
            4: {
                "name": "Supervised Fine-tuning",
                "description": "ç›‘ç£å¾®è°ƒ",
                "config_file": "configs/sts_finetune_stage4_demo.yaml", 
                "input_model": None,  # å°†åœ¨è¿è¡Œæ—¶è®¾ç½®ä¸ºstage3çš„è¾“å‡º
                "output_dir": self.output_root / f"stage4_{self.timestamp}",
                "epochs": 2,
            }
        }

    def setup_environment(self):
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®è®­ç»ƒç¯å¢ƒ...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env_vars = {
            "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:128,expandable_segments:True",
            "CUDA_LAUNCH_BLOCKING": "1",
            "PYTHONPATH": f"{self.project_root}/third_party/GLM-4-Voice:{os.environ.get('PYTHONPATH', '')}",
            "CUDA_VISIBLE_DEVICES": "0",
            # ç¦ç”¨ç”¨æˆ·çº§ site-packagesï¼Œé¿å…æ··å…¥ /home/linux/.local ä¸‹çš„ Python 3.10 åŒ…
            "PYTHONNOUSERSITE": "1",
        }
        
        for key, value in env_vars.items():
            os.environ[key] = value
            print(f"   è®¾ç½® {key}={value}")
        
        # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
        os.chdir(self.project_root)
        print(f"   å·¥ä½œç›®å½•: {os.getcwd()}")

    def create_deepspeed_config(self):
        """åˆ›å»ºDeepSpeedé…ç½®æ–‡ä»¶"""
        config = {
            "fp16": {
                "enabled": True,
                "loss_scale": 0,
                "loss_scale_window": 1000,
                "initial_scale_power": 16,
                "hysteresis": 2,
                "min_loss_scale": 1
            },
            "zero_optimization": {
                "stage": 2,
                "allgather_partitions": True,
                "allgather_bucket_size": 5e8,
                "overlap_comm": True,
                "reduce_scatter": True,
                "reduce_bucket_size": 5e8,
                "contiguous_gradients": True
            },
            "optimizer": {
                "type": "AdamW",
                "params": {
                    "lr": self.config["learning_rate"],
                    "betas": [0.9, 0.999],
                    "eps": 1e-8,
                    "weight_decay": 0.01
                }
            },
            "scheduler": {
                "type": "WarmupLR",
                "params": {
                    "warmup_min_lr": 0,
                    "warmup_max_lr": self.config["learning_rate"],
                    "warmup_num_steps": self.config["warmup_steps"]
                }
            },
            "gradient_accumulation_steps": self.config["gradient_accumulation_steps"],
            "gradient_clipping": self.config["max_grad_norm"],
            "steps_per_print": 10,
            "train_batch_size": self.config["batch_size"] * self.config["gradient_accumulation_steps"],
            "train_micro_batch_size_per_gpu": self.config["batch_size"],
            "wall_clock_breakdown": False
        }
        
        config_path = self.project_root / "ds_config_rtx2080ti.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"   åˆ›å»ºDeepSpeedé…ç½®: {config_path}")
        return config_path

    def run_training_stage(self, stage_num):
        """è¿è¡ŒæŒ‡å®šçš„è®­ç»ƒé˜¶æ®µ"""
        stage = self.stages[stage_num]
        print(f"\nğŸš€ å¼€å§‹Stage {stage_num}: {stage['name']}")
        print(f"   æè¿°: {stage['description']}")
        print(f"   è¾“å…¥æ¨¡å‹: {stage['input_model']}")
        print(f"   è¾“å‡ºç›®å½•: {stage['output_dir']}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        stage['output_dir'].mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤ - åŸºäºåŸå§‹shellè„šæœ¬
        ds_config = self.create_deepspeed_config()
        
        cmd = [
            sys.executable, "-m", "torch.distributed.run",
            "--nproc_per_node=1",
            "--nnodes=1", 
            "--node_rank=0",
            "--master_addr=localhost",
            "--master_port=29500",
            "tools/finetune_sts_v4_48_3.py",
            "--log_level", "info",
            "--do_train",
            "--overwrite_output_dir",
            "--tokenizer_name", str(stage['input_model']),
            "--model_name_or_path", str(stage['input_model']),
            "--audio_tokenizer_path", "/data/models/THUDM/glm-4-voice-tokenizer",
            "--audio_tokenizer_type", "sensevoice_glm4voice",
            "--dataset_name", f"configs/sts_finetune_stage{stage_num}_demo.yaml",
            "--bf16", "False",  # RTX 2080 Ti å…¼å®¹
            "--fp16", "True",
            "--output_dir", str(stage['output_dir']),
            "--num_train_epochs", str(stage['epochs']),
            "--per_device_train_batch_size", str(self.config['batch_size']),
            "--per_device_eval_batch_size", str(self.config['batch_size']),
            "--gradient_accumulation_steps", str(self.config['gradient_accumulation_steps']),
            "--evaluation_strategy", "no",
            "--save_strategy", "steps",
            "--save_steps", str(self.config['save_steps']),
            "--save_total_limit", "3",
            "--learning_rate", str(self.config['learning_rate']),
            "--weight_decay", "0.01",
            "--warmup_steps", str(self.config['warmup_steps']),
            "--lr_scheduler_type", "cosine",
            "--logging_steps", "10",
            "--model_max_length", str(self.config['seq_length']),
            "--gradient_checkpointing", "True",
            "--dataloader_num_workers", str(self.config['dataloader_num_workers']),
            "--report_to", "none",
            "--trust_remote_code", "True",
            "--attn_implementation", "eager",  # RTX 2080 Ti å…¼å®¹
            "--deepspeed", str(ds_config),  # å¯ç”¨DeepSpeed
            "--text-audio-interval-ratio", "1", "10", "4", "10",
            "--reset_attention_mask",
            "--reset_position_ids",
            "--create_attention_mask", "false",
            "--create_attention_mask_2d", "false",
        ]
        
        print(f"   æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # è¿è¡Œè®­ç»ƒ
        start_time = time.time()
        
        try:
            result = subprocess.run(
                cmd, 
                cwd=self.project_root,
                capture_output=False,
                text=True,
                check=True
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"\nâœ… Stage {stage_num} å®Œæˆï¼")
            print(f"   ç”¨æ—¶: {duration/3600:.2f} å°æ—¶")
            
            # è®¾ç½®ä¸‹ä¸€é˜¶æ®µçš„è¾“å…¥æ¨¡å‹
            if stage_num < 4:
                self.stages[stage_num + 1]['input_model'] = str(stage['output_dir'])
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ Stage {stage_num} å¤±è´¥ï¼")
            print(f"   é”™è¯¯ç : {e.returncode}")
            return False

    def run_all_stages(self, start_stage=1, end_stage=4):
        """è¿è¡Œæ‰€æœ‰è®­ç»ƒé˜¶æ®µ"""
        print("ğŸ¯ å¼€å§‹VITA-Audioå››é˜¶æ®µè®­ç»ƒ")
        print(f"   åŸºç¡€æ¨¡å‹: {self.base_model_path}")
        print(f"   è®­ç»ƒé˜¶æ®µ: Stage {start_stage} åˆ° Stage {end_stage}")
        print(f"   æ—¶é—´æˆ³: {self.timestamp}")
        
        # è®¾ç½®ç¯å¢ƒ
        self.setup_environment()
        
        total_start_time = time.time()
        
        # ä¾æ¬¡è¿è¡Œå„é˜¶æ®µ
        for stage_num in range(start_stage, end_stage + 1):
            success = self.run_training_stage(stage_num)
            if not success:
                print(f"\nğŸ›‘ è®­ç»ƒåœ¨Stage {stage_num}å¤±è´¥ï¼Œåœæ­¢åç»­é˜¶æ®µ")
                return False
        
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        print(f"\nğŸ‰ å››é˜¶æ®µè®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
        print(f"   æ€»ç”¨æ—¶: {total_duration/3600:.2f} å°æ—¶")
        print(f"   æœ€ç»ˆæ¨¡å‹: {self.stages[end_stage]['output_dir']}")
        
        return True

def main():
    parser = argparse.ArgumentParser(description="VITA-Audio å››é˜¶æ®µè®­ç»ƒè„šæœ¬")
    parser.add_argument("--base_model", type=str, 
                       default="/home/linux/VITA/VITA-Audio/VITA-Audio-Balance",
                       help="åŸºç¡€æ¨¡å‹è·¯å¾„")
    parser.add_argument("--start_stage", type=int, default=1,
                       help="å¼€å§‹é˜¶æ®µ (1-4)")
    parser.add_argument("--end_stage", type=int, default=4, 
                       help="ç»“æŸé˜¶æ®µ (1-4)")
    parser.add_argument("--seq_length", type=int, default=32768,
                       help="åºåˆ—é•¿åº¦")
    parser.add_argument("--batch_size", type=int, default=4,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=1e-5,
                       help="å­¦ä¹ ç‡")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = VITAAudioTrainer(base_model_path=args.base_model)
    
    # æ›´æ–°é…ç½®
    trainer.config.update({
        "seq_length": args.seq_length,
        "batch_size": args.batch_size,
        "learning_rate": args.learning_rate,
    })
    
    # è¿è¡Œè®­ç»ƒ
    success = trainer.run_all_stages(args.start_stage, args.end_stage)
    
    if success:
        print("\nğŸŠ æ­å–œï¼VITA-Audioè®­ç»ƒæˆåŠŸå®Œæˆï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ è®­ç»ƒå¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    main()
